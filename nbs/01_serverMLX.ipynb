{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# serverMLX\n",
    "\n",
    "> FASTAPI image uploader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp serverMLX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process the image for generating `mlx-community/Qwen2.5-VL-7B-Instruct-bf16`.<br>\n",
    "As it has a upper limit to process image `1280*28*28` and image need to be saved these are few helper fuction to achive this. It is for running inference mlx. The code is not shown here can be viewed in the git repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "prompt =  \"\"\"You are an AI specialized in recognizing and extracting text from all images in markdown format.\n",
    "Your mission is to analyze the image document and generate the result while maintaining data integrity.Extract the each text in details as present. \n",
    "It is mission critical. Do not send anything extra. DO NOT MISS ANY INFORMATION. Double check.\"\"\"\n",
    "\n",
    "if sys.platform == \"darwin\":  # init iff the code is running in mac\n",
    "    from finfox.core import *\n",
    "    import mlx.core as mx\n",
    "    from mlx_vlm import load, generate\n",
    "    from mlx_vlm.prompt_utils import apply_chat_template, get_message_json\n",
    "    from mlx_vlm.utils import load_config\n",
    "    # Load the model\n",
    "    #m_pth = \"mlx-community/Qwen2.5-VL-7B-Instruct-bf16\"\n",
    "    m_pth = \"mlx-community/Qwen2.5-VL-7B-Instruct-8bit\"\n",
    "    m_pth = \"mlx-community/Qwen2.5-VL-7B-Instruct-4bit\"\n",
    "    m_pth = \"mlx-community/Qwen2.5-VL-7B-Instruct-3bit\"\n",
    "\n",
    "    model, processor = load(m_pth)\n",
    "    config = load_config(m_pth)\n",
    "\n",
    "    formatted_prompt = apply_chat_template(\n",
    "            processor, config, prompt, num_images=1\n",
    "        )\n",
    "    \n",
    "    mx.eval(model.parameters()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastAPI upload image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import List\n",
    "from PIL import Image\n",
    "if sys.platform == \"darwin\":  \n",
    "\n",
    "    from fastapi import FastAPI, UploadFile, File, Header, Query\n",
    "    import io\n",
    "    from fastcore.all import *\n",
    "\n",
    "    app = FastAPI()\n",
    "\n",
    "    @app.post(\"/upload/\")\n",
    "    async def upload_image(\n",
    "        files: List[UploadFile] = File(...),\n",
    "        N: int = Query(..., alias=\"N\")):\n",
    "        \n",
    "        im_li = []\n",
    "        for i, file in enumerate(files):\n",
    "            # Read the image\n",
    "            data = await file.read()\n",
    "            im = Image.open(io.BytesIO(data))\n",
    "            fn = f\"temp_{N}_{i}.png\"\n",
    "            qwen_resize(im, limit=256*3*28*28, fn=fn)\n",
    "            im_li.append(fn)\n",
    "        \n",
    "        if sys.platform == \"darwin\":  \n",
    "            return generate(model, \n",
    "                            processor, \n",
    "                            formatted_prompt,\n",
    "                            im_li, \n",
    "                            verbose=True, \n",
    "                            max_tokens=4_056, \n",
    "                            repetition_penalty=1.1,\n",
    "                            temperature=0.2 \n",
    "                        )\n",
    "        \n",
    "        return [len(im_li)]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import httpx\n",
    "    \n",
    "\n",
    "async def test_server(images: List[Image.Image], N:int, url=\"http://localhost:9000/upload/\"):\n",
    "    \"\"\"\n",
    "    check uploading image to the server\n",
    "    \"\"\"\n",
    "    try:\n",
    "        files = []\n",
    "        for i, img in enumerate(images):\n",
    "            try:\n",
    "                img_copy = img.copy()\n",
    "                \n",
    "                byte_arr = io.BytesIO()\n",
    "                img_copy.save(byte_arr, format='PNG')\n",
    "                byte_arr.seek(0)\n",
    "                \n",
    "                files.append(('files', (f'image_{i}.png', byte_arr.getvalue(), 'image/png')))\n",
    "            except Exception as img_error:\n",
    "                print(f\"Error processing image {i}: {str(img_error)}\")\n",
    "                raise\n",
    "        \n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.post(url, \n",
    "                                         files=files, \n",
    "                                         headers= {\"N\":str(N)},\n",
    "                                         timeout=600.0)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                print(f\"Server response text: {response.text}\")\n",
    "                return None\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during upload: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#im = pdf2img(Path(\"t/ij.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = await test_server([im[5], im[6]], url=\"http://127.0.0.1:10000/upload/\")\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import aiohttp\n",
    "\n",
    "async def test_connection():\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            url = \"http://127.0.0.1:9000/openapi.json\"\n",
    "            print(f\"Trying {url}\")\n",
    "            async with session.get(url) as response:\n",
    "                print(f\"Status: {response.status}\")\n",
    "                return await response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"Connection error details: {type(e).__name__} - {str(e)}\")\n",
    "\n",
    "#await test_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
